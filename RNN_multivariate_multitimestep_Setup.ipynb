{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow.contrib.cudnn_rnn as cudnn_rnn\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "import tensorflow.contrib.layers as layers\n",
    "from tensorflow.python.util import nest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train test btach generator\n",
    "\n",
    "#Input and output placeholders\n",
    "\n",
    "\n",
    "#Model\n",
    "\n",
    "#loss\n",
    "\n",
    "#Runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_encoder(inputs, hidden_dim, num_stacked_layers, is_train=True, seed=123, output_transpose=True):\n",
    "    \"\"\"Build encoder for our RNN model\"\"\"\n",
    "    \n",
    "    #Expected input shape is batch_size, time sequence len, features\n",
    "    #params should have - num_layers, rnn_depth, dropout, \n",
    "    #Initalize weights\n",
    "\n",
    "    for i in range(num_stacked_layers):\n",
    "        with tf.variable_scope('RNN_{}'.format(i)):\n",
    "            cells.append(tf.contrib.rnn.GRUCell(hidden_dim))\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "        \n",
    "    enc_cell = copy.deepcopy(cell)\n",
    "    rnn_out, enc_state = tf.contrib.rnn.static_rnn(enc_cell, inputs, dtype=tf.float32)\n",
    "    c_state=None\n",
    "    if transpose_output:\n",
    "        rnn_out = tf.transpose(rnn_out, [1, 0, 2])\n",
    "        \n",
    "    return rnn_out, enc_state, c_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compressed_readout(rnn_out, attention_depth, dropout, seed):\n",
    "    \"\"\"\n",
    "    FC compression layer, reduces RNN output depth to hparams.attention_depth\n",
    "    :param rnn_out:\n",
    "    :param hparams:\n",
    "    :param dropout:\n",
    "    :param seed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if dropout < 1.0:\n",
    "        rnn_out = tf.nn.dropout(rnn_out, dropout, seed=seed)\n",
    "    return tf.layers.dense(rnn_out, attention_depth,\n",
    "                           use_bias=True,\n",
    "                           activation=tf.nn.selu,\n",
    "                           kernel_initializer=layers.variance_scaling_initializer(factor=1.0, seed=seed),\n",
    "                           name='compress_readout'\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_fingerprint(x, is_train, fc_dropout, seed):\n",
    "    \"\"\"\n",
    "    Calculates 'fingerprint' of timeseries, to feed into attention layer\n",
    "    :param x:\n",
    "    :param is_train:\n",
    "    :param fc_dropout:\n",
    "    :param seed:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(\"fingerpint\"):\n",
    "        # x = tf.expand_dims(x, -1)\n",
    "        with tf.variable_scope('convnet', initializer=layers.variance_scaling_initializer(seed=seed)):\n",
    "            c11 = tf.layers.conv1d(x, filters=16, kernel_size=7, activation=tf.nn.relu, padding='same')\n",
    "            c12 = tf.layers.conv1d(c11, filters=16, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "            pool1 = tf.layers.max_pooling1d(c12, 2, 2, padding='same')\n",
    "            c21 = tf.layers.conv1d(pool1, filters=32, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "            c22 = tf.layers.conv1d(c21, filters=32, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "            pool2 = tf.layers.max_pooling1d(c22, 2, 2, padding='same')\n",
    "            c31 = tf.layers.conv1d(pool2, filters=64, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "            c32 = tf.layers.conv1d(c31, filters=64, kernel_size=3, activation=tf.nn.relu, padding='same')\n",
    "            pool3 = tf.layers.max_pooling1d(c32, 2, 2, padding='same')\n",
    "            dims = pool3.shape.dims\n",
    "            pool3 = tf.reshape(pool3, [-1, dims[1].value * dims[2].value])\n",
    "            if is_train and fc_dropout < 1.0:\n",
    "                cnn_out = tf.nn.dropout(pool3, fc_dropout, seed=seed)\n",
    "            else:\n",
    "                cnn_out = pool3\n",
    "        with tf.variable_scope('fc_convnet',\n",
    "                               initializer=layers.variance_scaling_initializer(factor=1.0, mode='FAN_IN', seed=seed)):\n",
    "            fc_encoder = tf.layers.dense(cnn_out, 512, activation=tf.nn.selu, name='fc_encoder')\n",
    "            out_encoder = tf.layers.dense(fc_encoder, 16, activation=tf.nn.selu, name='out_encoder')\n",
    "    return out_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
